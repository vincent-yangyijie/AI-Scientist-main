#!/usr/bin/env python3
"""æµ‹è¯•Gemini-2.0-flashæ”¯æŒ"""

import os

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['GEMINI_API_KEY'] = 'AIzaSyCxaUNsUN9I9aTJImYdlVIa22xLoeEBN9k'

print("ğŸ§ª æµ‹è¯•Gemini-2.0-flashæ”¯æŒ")
print("="*40)

try:
    from ai_scientist.llm import AVAILABLE_LLMS, create_client, get_response_from_llm

    # æ£€æŸ¥æ˜¯å¦æ”¯æŒgemini-2.0-flash
    gemini_20_flash = 'gemini-2.0-flash'
    if gemini_20_flash in AVAILABLE_LLMS:
        print(f"âœ“ {gemini_20_flash} åœ¨æ”¯æŒåˆ—è¡¨ä¸­")

        # æµ‹è¯•å®¢æˆ·ç«¯åˆ›å»º
        print(f"\nğŸ”— åˆ›å»º {gemini_20_flash} å®¢æˆ·ç«¯...")
        client, model = create_client(gemini_20_flash)
        print(f"âœ“ å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {model}")

        # æ˜¾ç¤ºæ‰€æœ‰Geminiæ¨¡å‹
        gemini_models = [m for m in AVAILABLE_LLMS if 'gemini' in m]
        print(f"\nğŸ“‹ æ‰€æœ‰Geminiæ¨¡å‹ ({len(gemini_models)} ä¸ª):")
        for model in gemini_models:
            print(f"  â€¢ {model}")

        print(f"\nğŸ‰ {gemini_20_flash} å·²æˆåŠŸé›†æˆåˆ°AI Scientistä¸­!")

    else:
        print(f"âŒ {gemini_20_flash} ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")
        print("å¯ç”¨Geminiæ¨¡å‹:")
        for m in AVAILABLE_LLMS:
            if 'gemini' in m:
                print(f"  â€¢ {m}")

except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
